{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Bi-directional LSTM\n",
    "\n",
    "```\n",
    "Finished Evaluation [1]: Minibatch[1-1754]: metric = 0.00% * 2000;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "import cntk as C\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import cntk.tests.test_utils\n",
    "from cntk import input_variable, cross_entropy_with_softmax, \\\n",
    "        classification_error, sequence\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "C.cntk_py.set_fixed_random_seed(1)                 # fix a random seed for CNTK componentsk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dimensions\n",
    "input_dim =  23897\n",
    "num_output_classes = 2 \n",
    "features = sequence.input_variable(shape=input_dim, is_sparse=True)\n",
    "label = input_variable(num_output_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from cntk import Trainer, Axis\n",
    "from cntk.io import MinibatchSource, CTFDeserializer, StreamDef, StreamDefs,\\\n",
    "        INFINITELY_REPEAT\n",
    "from cntk.learners import adam, sgd, learning_rate_schedule, UnitType, momentum_as_time_constant_schedule\n",
    "from cntk import input_variable, cross_entropy_with_softmax, \\\n",
    "        classification_error, sequence\n",
    "from cntk.logging import ProgressPrinter\n",
    "from cntk.layers import Sequential, Embedding, Recurrence, LSTM, Dense, BatchNormalization\n",
    "\n",
    "# Creates the reader\n",
    "def create_reader(path, is_training, input_dim, label_dim):\n",
    "    \"\"\"\n",
    "        Creates a reader that loads data from file.\n",
    "        \n",
    "        Args:\n",
    "            path: is the relative path to the data file.\n",
    "            is_training: if reader is used for training\n",
    "            input_dim: the input dim of a word (vocab size)\n",
    "            label_dim: the number of classes\n",
    "    \"\"\"\n",
    "    return MinibatchSource(CTFDeserializer(path, StreamDefs(\n",
    "        features=StreamDef(field='S0', shape=input_dim, is_sparse=True),\n",
    "        labels=StreamDef(field='S1', shape=label_dim, is_sparse=False)\n",
    "        )), randomize=is_training,\n",
    "        max_sweeps=INFINITELY_REPEAT if is_training else 1)\n",
    "\n",
    "def create_criterion_function_preferred(model, labels):\n",
    "    \"\"\"\n",
    "        Creates a tuple of criterions, softmax and classification error\n",
    "        \n",
    "        Args:\n",
    "            model - that is being trained.\n",
    "            labels - labels to compare with (cntk Variable)\n",
    "        Returns:\n",
    "            Tuple of functions: (softmax, classification)\n",
    "    \"\"\"\n",
    "    ce   = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error      (model, labels)\n",
    "    \n",
    "    return ce, errs # (model, labels) -> (loss, error metric)\n",
    "\n",
    "def evaluate(reader, model_func):\n",
    "    \"\"\"\n",
    "        Evaluates the model given a reader (data source) and\n",
    "        the trained model.\n",
    "        \n",
    "        Args:\n",
    "            reader - data source that reads from files.\n",
    "            model_func - the trained model.\n",
    "    \"\"\"\n",
    "    # Instantiate the model function; x is the input (feature) variable\n",
    "    model = model_func(features)\n",
    "\n",
    "    # Create the loss and error functions\n",
    "    loss, label_error = create_criterion_function_preferred(model, label)\n",
    "\n",
    "    # process minibatches and perform evaluation\n",
    "    progress_printer = C.logging.ProgressPrinter(tag='Evaluation', num_epochs=0)\n",
    "  \n",
    "    results = []\n",
    "    while True:    \n",
    "        minibatch_size = 500\n",
    "        data = reader.next_minibatch(minibatch_size, input_map={  # fetch minibatch\n",
    "            features: reader.streams.features,\n",
    "            label: reader.streams.labels\n",
    "        })\n",
    "        if not data:                                 # until we hit the end\n",
    "            break\n",
    "\n",
    "        evaluator = C.eval.Evaluator(loss, progress_printer)\n",
    "        evaluator.test_minibatch(data)\n",
    "        results.extend(model.eval(data))\n",
    "        print data\n",
    "    evaluator.summarize_test_progress()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cntk import load_model\n",
    "loaded_model = load_model(\"imbd.v3-1.cntk.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Reached the maximum number of allowed errors while reading the input file (data/bbc/aggregated/bbc.init.test.ctf).\n\n[CALL STACK]\n    > Microsoft::MSR::CNTK::IDataReader::  SupportsDistributedMBRead\n    - Microsoft::MSR::CNTK::IDataReader::  SupportsDistributedMBRead (x5)\n    - CreateCompositeDataReader (x3)\n    - CNTK::Dictionary::  ~Dictionary (x5)\n    - Microsoft::MSR::CNTK::IDataReader::  operator= (x2)\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0bd7fe64ec8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-0bd7fe64ec8e>\u001b[0m in \u001b[0;36mdo_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"data/bbc/aggregated/bbc.init.test.ctf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-d995b2b95b71>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(reader, model_func)\u001b[0m\n\u001b[0;32m     63\u001b[0m         data = reader.next_minibatch(minibatch_size, input_map={  # fetch minibatch\n\u001b[0;32m     64\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstreams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         })\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m                                 \u001b[1;31m# until we hit the end\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\local\\Anaconda2-5.0.0\\lib\\site-packages\\cntk\\internal\\swig_helper.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m         \u001b[0mmap_if_possible\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\local\\Anaconda2-5.0.0\\lib\\site-packages\\cntk\\io\\__init__.pyc\u001b[0m in \u001b[0;36mnext_minibatch\u001b[1;34m(self, minibatch_size_in_samples, input_map, device, num_data_partitions, partition_index)\u001b[0m\n\u001b[0;32m    327\u001b[0m                                             \u001b[0mminibatch_size_in_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                                             \u001b[0mnum_data_partitions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m                                             partition_index, device)\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\local\\Anaconda2-5.0.0\\lib\\site-packages\\cntk\\cntk_py.pyc\u001b[0m in \u001b[0;36mget_next_minibatch\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   2915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2916\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2917\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinibatchSource_get_next_minibatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2918\u001b[0m \u001b[0mMinibatchSource_swigregister\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_cntk_py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinibatchSource_swigregister\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2919\u001b[0m \u001b[0mMinibatchSource_swigregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMinibatchSource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Reached the maximum number of allowed errors while reading the input file (data/bbc/aggregated/bbc.init.test.ctf).\n\n[CALL STACK]\n    > Microsoft::MSR::CNTK::IDataReader::  SupportsDistributedMBRead\n    - Microsoft::MSR::CNTK::IDataReader::  SupportsDistributedMBRead (x5)\n    - CreateCompositeDataReader (x3)\n    - CNTK::Dictionary::  ~Dictionary (x5)\n    - Microsoft::MSR::CNTK::IDataReader::  operator= (x2)\n\n"
     ]
    }
   ],
   "source": [
    "def do_test():\n",
    "    \"\"\" Tests the network on the validation set.\n",
    "    \"\"\"\n",
    "    input_dim =  23897\n",
    "    cell_dim = 50\n",
    "    hidden_dim = 150\n",
    "    embedding_dim = 100\n",
    "    num_output_classes = 2 \n",
    "    \n",
    "    path = (\"data/bbc/aggregated/bbc.init.test.ctf\")\n",
    "    reader = create_reader(path, False, input_dim, num_output_classes)\n",
    "    return evaluate(reader, loaded_model)\n",
    "results = do_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ..., 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "r = np.array(results)\n",
    "classifications = (np.argmax(r, axis=1))\n",
    "print classifications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
